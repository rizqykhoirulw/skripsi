{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128) (240, 128, 128) (300, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Memuat file .npy\n",
    "data_train = np.load('mhsma_dataset_master/mhsma/x_128_train.npy')\n",
    "data_valid = np.load('mhsma_dataset_master/mhsma/x_128_valid.npy')\n",
    "data_test = np.load('mhsma_dataset_master/mhsma/x_128_test.npy')\n",
    "\n",
    "# Memeriksa bentuk data\n",
    "print(data_train.shape, data_valid.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua gambar telah disimpan di folder folder train.\n",
      "Semua gambar telah disimpan di folder folder valid.\n",
      "Semua gambar telah disimpan di folder folder test.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Loop melalui setiap gambar dalam array dan simpan sebagai file .png\n",
    "for i in range(data_train.shape[0]):\n",
    "    # Asumsi data memiliki bentuk (jumlah_gambar, tinggi, lebar) atau (jumlah_gambar, tinggi, lebar, channel)\n",
    "    image = data_train[i]\n",
    "    \n",
    "    # Jika gambar grayscale (2D array), konversi ke format 8-bit\n",
    "    if image.ndim == 2:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    # Jika gambar berwarna (3D array), pastikan juga dikonversi ke format 8-bit\n",
    "    elif image.ndim == 3 and image.shape[2] == 3:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Simpan gambar sebagai file .png\n",
    "    output_path = os.path.join('dataset_flagel/train/', f'image_{i+1:03d}.png')\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f'Semua gambar telah disimpan di folder folder train.')\n",
    "\n",
    "for i in range(data_valid.shape[0]):\n",
    "    # Asumsi data memiliki bentuk (jumlah_gambar, tinggi, lebar) atau (jumlah_gambar, tinggi, lebar, channel)\n",
    "    image = data_valid[i]\n",
    "    \n",
    "    # Jika gambar grayscale (2D array), konversi ke format 8-bit\n",
    "    if image.ndim == 2:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    # Jika gambar berwarna (3D array), pastikan juga dikonversi ke format 8-bit\n",
    "    elif image.ndim == 3 and image.shape[2] == 3:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Simpan gambar sebagai file .png\n",
    "    output_path = os.path.join('dataset_flagel/valid/', f'image_{i+1:03d}.png')\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f'Semua gambar telah disimpan di folder folder valid.')\n",
    "\n",
    "for i in range(data_test.shape[0]):\n",
    "    # Asumsi data memiliki bentuk (jumlah_gambar, tinggi, lebar) atau (jumlah_gambar, tinggi, lebar, channel)\n",
    "    image = data_test[i]\n",
    "    \n",
    "    # Jika gambar grayscale (2D array), konversi ke format 8-bit\n",
    "    if image.ndim == 2:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    # Jika gambar berwarna (3D array), pastikan juga dikonversi ke format 8-bit\n",
    "    elif image.ndim == 3 and image.shape[2] == 3:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Simpan gambar sebagai file .png\n",
    "    output_path = os.path.join('dataset_flagel/test/', f'image_{i+1:03d}.png')\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f'Semua gambar telah disimpan di folder folder test.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi label selesai dan disimpan dalam folder 'train'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Memuat file npy\n",
    "y_tail_train = np.load('mhsma_dataset_master/mhsma/y_tail_train.npy')\n",
    "y_tail_valid = np.load('mhsma_dataset_master/mhsma/y_tail_valid.npy')\n",
    "y_tail_test = np.load('mhsma_dataset_master/mhsma/y_tail_test.npy')\n",
    "\n",
    "for idx, label in enumerate(y_tail_train):\n",
    "    # Buat nama file unik untuk setiap label\n",
    "    idx_plus_one = idx + 1\n",
    "    filename = f'dataset_biner_flagel/train/image_{idx_plus_one:03}.txt'\n",
    "    \n",
    "    # Menulis label ke file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(str(label))\n",
    "\n",
    "for idx, label in enumerate(y_tail_valid):\n",
    "    # Buat nama file unik untuk setiap label\n",
    "    idx_plus_one = idx + 1\n",
    "    filename = f'dataset_biner_flagel/valid/image_{idx_plus_one:03}.txt'\n",
    "    \n",
    "    # Menulis label ke file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(str(label))\n",
    "\n",
    "for idx, label in enumerate(y_tail_test):\n",
    "    # Buat nama file unik untuk setiap label\n",
    "    idx_plus_one = idx + 1\n",
    "    filename = f'dataset_biner_flagel/test/image_{idx_plus_one:03}.txt'\n",
    "    \n",
    "    # Menulis label ke file\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(str(label))\n",
    "\n",
    "print(\"Ekstraksi label selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Fungsi untuk resize dan normalisasi gambar\n",
    "def preprocess_images_valid(valid_folder, valid_output, target_size=(512, 512)):\n",
    "    # if not os.path.exists(output_folder):\n",
    "    #     os.makedirs(output_folder)\n",
    "    \n",
    "    for image_name in os.listdir(valid_folder):\n",
    "        img_path = os.path.join(valid_folder, image_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            # Resize gambar\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            # Normalisasi gambar\n",
    "            img_normalized = img_resized / 255.0\n",
    "            # Simpan hasil preprocessing\n",
    "            cv2.imwrite(os.path.join(valid_output, image_name), img_normalized * 255)\n",
    "\n",
    "def preprocess_images_train(train_folder, train_output, target_size=(512, 512)):\n",
    "    # if not os.path.exists(output_folder):\n",
    "    #     os.makedirs(output_folder)\n",
    "    \n",
    "    for image_name in os.listdir(train_folder):\n",
    "        img_path = os.path.join(train_folder, image_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            # Resize gambar\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            # Normalisasi gambar\n",
    "            img_normalized = img_resized / 255.0\n",
    "            # Simpan hasil preprocessing\n",
    "            cv2.imwrite(os.path.join(train_output, image_name), img_normalized * 255)\n",
    "\n",
    "def preprocess_images_test(test_folder, test_output, target_size=(512, 512)):\n",
    "    # if not os.path.exists(output_folder):\n",
    "    #     os.makedirs(output_folder)\n",
    "    \n",
    "    for image_name in os.listdir(test_folder):\n",
    "        img_path = os.path.join(test_folder, image_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is not None:\n",
    "            # Resize gambar\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            # Normalisasi gambar\n",
    "            img_normalized = img_resized / 255.0\n",
    "            # Simpan hasil preprocessing\n",
    "            cv2.imwrite(os.path.join(test_output, image_name), img_normalized * 255)\n",
    "\n",
    "# Path folder gambar asli dan folder output\n",
    "train_folder = 'dataset_flagel/train'\n",
    "train_output = 'dataset_flagel/train_output'\n",
    "valid_folder = 'dataset_flagel/valid'\n",
    "valid_output = 'dataset_flagel/valid_output'\n",
    "test_folder = 'dataset_flagel/test'\n",
    "test_output = 'dataset_flagel/test_output'\n",
    "preprocess_images_train(train_folder, train_output)\n",
    "preprocess_images_valid(valid_folder, valid_output)\n",
    "preprocess_images_test(test_folder, test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def resize_annotation(xml_file, factor, output_path):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for bndbox in root.iter('bndbox'):\n",
    "        bndbox.find('xmin').text = str(int(int(bndbox.find('xmin').text) * factor))\n",
    "        bndbox.find('ymin').text = str(int(int(bndbox.find('ymin').text) * factor))\n",
    "        bndbox.find('xmax').text = str(int(int(bndbox.find('xmax').text) * factor))\n",
    "        bndbox.find('ymax').text = str(int(int(bndbox.find('ymax').text) * factor))\n",
    "\n",
    "    # Ambil nama file tanpa extension\n",
    "    xml_filename = os.path.basename(xml_file)\n",
    "    # Simpan file XML di folder output yang sama dengan gambar yang sudah di-resize\n",
    "    output_xml_file = os.path.join(output_path, xml_filename)\n",
    "    tree.write(output_xml_file)\n",
    "\n",
    "# def resize_annotation_valid(xml_file, factor, output_path):\n",
    "#     tree = ET.parse(xml_file)\n",
    "#     root = tree.getroot()\n",
    "\n",
    "#     for bndbox in root.iter('bndbox'):\n",
    "#         bndbox.find('xmin').text = str(int(int(bndbox.find('xmin').text) * factor))\n",
    "#         bndbox.find('ymin').text = str(int(int(bndbox.find('ymin').text) * factor))\n",
    "#         bndbox.find('xmax').text = str(int(int(bndbox.find('xmax').text) * factor))\n",
    "#         bndbox.find('ymax').text = str(int(int(bndbox.find('ymax').text) * factor))\n",
    "\n",
    "#     # Ambil nama file tanpa extension\n",
    "#     xml_filename = os.path.basename(xml_file)\n",
    "#     # Simpan file XML di folder output yang sama dengan gambar yang sudah di-resize\n",
    "#     output_xml_file = os.path.join(output_path, xml_filename)\n",
    "#     tree.write(output_xml_file)\n",
    "\n",
    "# def resize_annotation_test(xml_file, factor, output_path):\n",
    "#     tree = ET.parse(xml_file)\n",
    "#     root = tree.getroot()\n",
    "\n",
    "#     for bndbox in root.iter('bndbox'):\n",
    "#         bndbox.find('xmin').text = str(int(int(bndbox.find('xmin').text) * factor))\n",
    "#         bndbox.find('ymin').text = str(int(int(bndbox.find('ymin').text) * factor))\n",
    "#         bndbox.find('xmax').text = str(int(int(bndbox.find('xmax').text) * factor))\n",
    "#         bndbox.find('ymax').text = str(int(int(bndbox.find('ymax').text) * factor))\n",
    "\n",
    "#     # Ambil nama file tanpa extension\n",
    "#     xml_filename = os.path.basename(xml_file)\n",
    "#     # Simpan file XML di folder output yang sama dengan gambar yang sudah di-resize\n",
    "#     output_xml_file = os.path.join(output_path, xml_filename)\n",
    "#     tree.write(output_xml_file)\n",
    "\n",
    "factor = 512 / 128\n",
    "annotations_path_train = 'dataset_flagel/train'  \n",
    "output_annotations_path_train = 'dataset_flagel/train_output' \n",
    "annotations_path_valid = 'dataset_flagel/valid'  \n",
    "output_annotations_path_valid = 'dataset_flagel/valid_output'  \n",
    "annotations_path_test = 'dataset_flagel/test'  \n",
    "output_annotations_path_test = 'dataset_flagel/test_output' \n",
    "\n",
    "\n",
    "# Resize setiap file XML dan simpan hasilnya di folder output\n",
    "\n",
    "for xml_file in os.listdir(annotations_path_train):\n",
    "    if xml_file.endswith('.xml'):  # Pastikan file adalah XML\n",
    "        resize_annotation(os.path.join(annotations_path_train, xml_file), factor, output_annotations_path_train)\n",
    "for xml_file in os.listdir(annotations_path_valid):\n",
    "    if xml_file.endswith('.xml'):  # Pastikan file adalah XML\n",
    "        resize_annotation(os.path.join(annotations_path_valid, xml_file), factor, output_annotations_path_valid)\n",
    "for xml_file in os.listdir(annotations_path_test):\n",
    "    if xml_file.endswith('.xml'):  # Pastikan file adalah XML\n",
    "        resize_annotation(os.path.join(annotations_path_test, xml_file), factor, output_annotations_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created TFRecord file: train.tfrecord\n",
      "Successfully created TFRecord file: valid.tfrecord\n",
      "Successfully created TFRecord file: test.tfrecord\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from object_detection.utils import dataset_util\n",
    "from PIL import Image\n",
    "\n",
    "def create_tf_example(image_path, xml_path, label_map_dict):\n",
    "    # Baca gambar\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    img_format = image_path.split('.')[-1].encode('utf8')\n",
    "    \n",
    "    with tf.io.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "\n",
    "    # Baca file anotasi XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    filename = root.find('filename').text.encode('utf8')\n",
    "    \n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        classes_text.append(class_name.encode('utf8'))\n",
    "        classes.append(label_map_dict[class_name])\n",
    "        \n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmins.append(float(bndbox.find('xmin').text) / width)\n",
    "        xmaxs.append(float(bndbox.find('xmax').text) / width)\n",
    "        ymins.append(float(bndbox.find('ymin').text) / height)\n",
    "        ymaxs.append(float(bndbox.find('ymax').text) / height)\n",
    "\n",
    "    # Membuat TFRecord Example\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(img_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "def convert_to_tfrecord(output_path, image_folder, annotation_folder, label_map_dict):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    \n",
    "    for xml_file in glob.glob(os.path.join(annotation_folder, \"*.xml\")):\n",
    "        image_name = os.path.splitext(os.path.basename(xml_file))[0] + \".png\"  # Adjust for your image format\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_path} not found, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        tf_example = create_tf_example(image_path, xml_file, label_map_dict)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    print(f\"Successfully created TFRecord file: {output_path}\")\n",
    "\n",
    "# Map kelas ke id (pastikan sesuai dengan label_map.txt)\n",
    "label_map_dict = {\n",
    "    'normal': 0,\n",
    "    'abnormal': 1,\n",
    "    # Tambahkan kelas lain jika ada\n",
    "}\n",
    "\n",
    "# Path untuk menyimpan TFRecord\n",
    "train_output_path = 'train.tfrecord'\n",
    "valid_output_path = 'valid.tfrecord'\n",
    "test_output_path = 'test.tfrecord'\n",
    "\n",
    "# Path ke folder dataset\n",
    "train_image_folder = 'dataset_flagel/train_output/images'\n",
    "train_annotation_folder = 'dataset_flagel/train_output/anotate'\n",
    "\n",
    "valid_image_folder = 'dataset_flagel/valid_output/images'\n",
    "valid_annotation_folder = 'dataset_flagel/valid_output/anotate'\n",
    "\n",
    "test_image_folder = 'dataset_flagel/test_output/images'\n",
    "test_annotation_folder = 'dataset_flagel/test_output/anotate'\n",
    "\n",
    "# Konversi dataset ke TFRecord\n",
    "convert_to_tfrecord(train_output_path, train_image_folder, train_annotation_folder, label_map_dict)\n",
    "convert_to_tfrecord(valid_output_path, valid_image_folder, valid_annotation_folder, label_map_dict)\n",
    "convert_to_tfrecord(test_output_path, test_image_folder, test_annotation_folder, label_map_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficientdet-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
